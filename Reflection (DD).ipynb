{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Fourteen: Project Design Starter\n",
    "In this exercise, you'll be planning out a complex project. You'll draw in some code, but focus on commenting to describe your project structure. The sample document below will guide you through organizing and annotating your project design. The primary components you'll include are:\n",
    "\n",
    "- Dependencies: What modules will your project need?\n",
    "- Collection: Where is your data coming from?\n",
    "- Processing: How will you format and process your data?\n",
    "- Analysis: What techniques will you use to understand your data?\n",
    "- Visualization: How will you visualize and explore your data?\n",
    "\n",
    "Don't worry if you aren't exactly certain how you would implement everything - this should be a starting point for a larger research study, but it doesn't need to be a complete, functional workflow. Aim for a \"good enough\" starting point that you can reference and extend for future work.\n",
    "\n",
    "Note where you have something working, and where it's broken or in progress.\n",
    "\n",
    "And to help push the technical philosophy further and keep the process moving was knowing that \"An interface is a set of cognitive cues. It may look like a screen full of pictures of things inside the computer, but in fact, the interface mediates between an individual the computational activity\" (Drucker 176).\n",
    "\n",
    "\"When people change how they speak or act in order to conform to dominant norms, we call it “code-switching”\" (Benjamin 180). \n",
    "\n",
    "\"Data, in short, do not speak for themselves and don’t always change hearts and minds or policy\" (Benjamin 192). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS Project Overview: IMDb\n",
    "\n",
    "Using Beautiful Soup, I wanted to show the process of bringing in the elements scraped from IMDb data for this inquiry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Stage One: Dependencies\n",
    "\n",
    "As a result, comfort has been established as BeautifulSoup enables movement to work without an API. Enforcing beginning with \"a problem or a question. If your problem or question is not well defined, develop or find one which is\" (Karsdorp, Kestemont, Riddell 323) comes alive.\n",
    "\n",
    "With the help of the path being \"director/,\" I was off and running, as \"An interface can connect a person with a computer.., a computer with a computer (as in an API)\" (Drucker 172).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than representing my abbreviations of identity, IMDb is an Amazon setup toward the entertainment industry about film and cinema. I am bringing information attainable at the primary level toward consumer interest of film backgrounds to IMDb Pro stipulations that aid industry searches toward gaining knowledge and industry contacts. And with the enforcement of Beautiful Soup, the process begins packaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Package imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "import concurrent.futures\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url= \"https://www.imdb.com/search/title?count=100&title_type=feature,tv_series&ref_=nv_wl_img_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Python's API, the need to draw IMDb data from an abundance of online URLs is accomplished with the \"Thread\" directional tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of threads that will be spawned\n",
    "MAX_THREADS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below were the adjustments made with the focus of attributes of interest ranging from \"movie_title_arr\" to \"image_id_arr.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title_arr = []\n",
    "movie_year_arr = []\n",
    "movie_genre_arr = []\n",
    "movie_synopsis_arr =[]\n",
    "image_url_arr  = []\n",
    "image_id_arr = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below was the phase of Scraping the elements above collected toward introducing us to Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieTitle(header):\n",
    "    try:\n",
    "        return header[0].find(\"a\").getText()\n",
    "    except:\n",
    "        return 'NA'\n",
    "\n",
    "def getReleaseYear(header):\n",
    "    try:\n",
    "        return header[0].find(\"span\",  {\"class\": \"lister-item-year text-muted unbold\"}).getText()\n",
    "    except:\n",
    "        return 'NA'\n",
    "\n",
    "def getGenre(muted_text):\n",
    "    try:\n",
    "        return muted_text.find(\"span\",  {\"class\":  \"genre\"}).getText()\n",
    "    except:\n",
    "        return 'NA'\n",
    "\n",
    "def getsynopsys(movie):\n",
    "    try:\n",
    "        return movie.find_all(\"p\", {\"class\":  \"text-muted\"})[1].getText()\n",
    "    except:\n",
    "        return 'NA'\n",
    "\n",
    "def getImage(image):\n",
    "    try:\n",
    "        return image.get('loadlate')\n",
    "    except:\n",
    "        return 'NA'\n",
    "\n",
    "def getImageId(image):\n",
    "    try:\n",
    "        return image.get('data-tconst')\n",
    "    except:\n",
    "        return 'NA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through IMDb data, the foster function responsible for iteration is derived. Now, extraction occurs and formulates. URL elements are then explored and filtered to push this journey forward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(imdb_url):\n",
    "    response = requests.get(imdb_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Movie Name\n",
    "    movies_list  = soup.find_all(\"div\", {\"class\": \"lister-item mode-advanced\"})\n",
    "    \n",
    "    for movie in movies_list:\n",
    "        header = movie.find_all(\"h3\", {\"class\":  \"lister-item-header\"})\n",
    "        muted_text = movie.find_all(\"p\", {\"class\":  \"text-muted\"})[0]\n",
    "        imageDiv =  movie.find(\"div\", {\"class\": \"lister-item-image float-left\"})\n",
    "        image = imageDiv.find(\"img\", \"loadlate\")\n",
    "        \n",
    "        #  Movie Title\n",
    "        movie_title =  getMovieTitle(header)\n",
    "        movie_title_arr.append(movie_title)\n",
    "        \n",
    "        #  Movie release year\n",
    "        year = getReleaseYear(header)\n",
    "        movie_year_arr.append(year)\n",
    "        \n",
    "        #  Genre  of movie\n",
    "        genre = getGenre(muted_text)\n",
    "        movie_genre_arr.append(genre)\n",
    "        \n",
    "        # Movie Synopsys\n",
    "        synopsis = getsynopsys(movie)\n",
    "        movie_synopsis_arr.append(synopsis)\n",
    "        \n",
    "        #  Image attributes\n",
    "        img_url = getImage(image)\n",
    "        image_url_arr.append(img_url)\n",
    "        \n",
    "        image_id = image.get('data-tconst')\n",
    "        image_id_arr.append(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progression is realized assembled below in the relational URLs formulating filtered films. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "251\n",
      "501\n",
      "751\n",
      "1001\n",
      "1251\n",
      "1501\n",
      "1751\n",
      "2001\n",
      "2251\n",
      "2501\n",
      "2751\n",
      "3001\n",
      "3251\n",
      "3501\n",
      "3751\n",
      "4001\n",
      "4251\n",
      "4501\n",
      "4751\n",
      "5001\n",
      "5251\n",
      "5501\n",
      "5751\n",
      "6001\n",
      "6251\n",
      "6501\n",
      "6751\n",
      "7001\n",
      "7251\n",
      "7501\n",
      "7751\n",
      "8001\n",
      "8251\n",
      "8501\n",
      "8751\n",
      "9001\n",
      "9251\n",
      "9501\n",
      "9751\n",
      "10001\n",
      "10251\n",
      "10501\n",
      "10751\n",
      "11001\n",
      "11251\n",
      "11501\n",
      "11751\n",
      "12001\n",
      "12251\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "# An array to store all the URL that are being queried\n",
    "imageArr = []\n",
    "\n",
    "# Maximum number of pages one wants to iterate over\n",
    "MAX_PAGE =51\n",
    "\n",
    "# Loop to generate all the URLS.\n",
    "for i in range(0,MAX_PAGE):\n",
    "    totalRecords = 0 if i==0 else (250*i)+1\n",
    "    print(totalRecords)\n",
    "    imdb_url = f'https://www.imdb.com/search/title/?release_date=2020-01-02,2021-02-01&user_rating=4.0,10.0&languages=en&count=250&start={totalRecords}&ref_=adv_nxt'\n",
    "    imageArr.append(imdb_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloading function of \"download_stories\"  brings the URLs toward a primary function teamed up with the \"MAX_THREADS\" number of acceptance of requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stories(story_urls):\n",
    "    threads = min(MAX_THREADS, len(story_urls))\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "        executor.map(main, story_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, the download function progresses our pursuit toward attaining the required and requested data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the download function with the array of URLS called imageArr\n",
    "download_stories(imageArr)\n",
    "\n",
    "# Attach all the data to the pandas dataframe. You can optionally write it to a CSV file as well\n",
    "movieDf = pd.DataFrame({\n",
    "    \"Title\": movie_title_arr,\n",
    "    \"Release_Year\": movie_year_arr,\n",
    "    \"Genre\": movie_genre_arr,\n",
    "    \"Synopsis\": movie_synopsis_arr,\n",
    "    \"image_url\": image_url_arr,\n",
    "    \"image_id\": image_id_arr,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, IMDB is attainable and readable toward analyzing a progressed data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Download Complete CSV Formed --------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Release_Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Great</td>\n",
       "      <td>(2020– )</td>\n",
       "      <td>\\nBiography, Comedy, Drama</td>\n",
       "      <td>\\nA royal woman living in rural Russia during ...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYzVmOG...</td>\n",
       "      <td>tt2235759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bruised</td>\n",
       "      <td>(2020)</td>\n",
       "      <td>\\nDrama, Sport</td>\n",
       "      <td>\\nA disgraced MMA fighter finds redemption in ...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMWRjZG...</td>\n",
       "      <td>tt8310474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ted Lasso</td>\n",
       "      <td>(2020– )</td>\n",
       "      <td>\\nComedy, Drama, Sport</td>\n",
       "      <td>\\nAmerican college football coach Ted Lasso he...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMDVmOD...</td>\n",
       "      <td>tt10986410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Locke &amp; Key</td>\n",
       "      <td>(2020– )</td>\n",
       "      <td>\\nDrama, Fantasy, Horror</td>\n",
       "      <td>\\nAfter their father is murdered under mysteri...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BNmYyNW...</td>\n",
       "      <td>tt3007572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Little Things</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>\\nCrime, Drama, Mystery</td>\n",
       "      <td>\\nKern County Deputy Sheriff Joe Deacon is sen...</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BOGFlNT...</td>\n",
       "      <td>tt10016180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title Release_Year                                   Genre  \\\n",
       "0          The Great     (2020– )  \\nBiography, Comedy, Drama               \n",
       "1            Bruised       (2020)              \\nDrama, Sport               \n",
       "2          Ted Lasso     (2020– )      \\nComedy, Drama, Sport               \n",
       "3        Locke & Key     (2020– )    \\nDrama, Fantasy, Horror               \n",
       "4  The Little Things       (2021)     \\nCrime, Drama, Mystery               \n",
       "\n",
       "                                            Synopsis  \\\n",
       "0  \\nA royal woman living in rural Russia during ...   \n",
       "1  \\nA disgraced MMA fighter finds redemption in ...   \n",
       "2  \\nAmerican college football coach Ted Lasso he...   \n",
       "3  \\nAfter their father is murdered under mysteri...   \n",
       "4  \\nKern County Deputy Sheriff Joe Deacon is sen...   \n",
       "\n",
       "                                           image_url    image_id  \n",
       "0  https://m.media-amazon.com/images/M/MV5BYzVmOG...   tt2235759  \n",
       "1  https://m.media-amazon.com/images/M/MV5BMWRjZG...   tt8310474  \n",
       "2  https://m.media-amazon.com/images/M/MV5BMDVmOD...  tt10986410  \n",
       "3  https://m.media-amazon.com/images/M/MV5BNmYyNW...   tt3007572  \n",
       "4  https://m.media-amazon.com/images/M/MV5BOGFlNT...  tt10016180  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('--------- Download Complete CSV Formed --------')\n",
    "\n",
    "# movie.to_csv('file.csv', index=False) : If you want to store the file.\n",
    "movieDf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Synopsis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_100744/3710159887.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSynopsis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Topic 2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Synopsis' is not defined"
     ]
    }
   ],
   "source": [
    "words = Synopsis.loc['Topic 2'].sort_values(ascending=False).head(18)\n",
    "words \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "print(Synopsis.loc['Topic 2'].head(20))\n",
    "\n",
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate_from_frequencies(words)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598d64e08a06bfba065a99698ec5bbec753236817de80e4f3bcf221574aa140c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
