{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Exercise Thirteen: Interface\n",
    "This week, you'll be revisiting a database (such as our example, gathered from Tweepy) and exploring methods for visualizing the data to others. Your exercise should:\n",
    "\n",
    "- Import or collect your data as appropriate, using OS or an API\n",
    "- Make and structure your data in a Pandas dataframe\n",
    "- Use NLTK to tokenize the data, and chart a word cloud\n",
    "- Create a \"wordcloud of interest\" by playing with the visualization methods from the class demo, or others documented in the API\n",
    "- Import Bokeh and chart some aspect of the text: this could be the wordcount, topics, or sentiment analysis as demoed\n",
    "\n",
    "Consider exploring other visualization types in the Bokeh API documentation, and play with the color options and scale of your visualization.\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage One: Import or collect your data as appropriate, using OS or an API\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documented at: https://towardsdatascience.com/web-scraping-metacritic-reviews-using-beautifulsoup-63801bbe200e\n",
    "#we're going back to week six to import reviews, but this time we're getting all of them!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Two: Make and structure your data in a Pandas dataframe\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict = {'name':[], 'date':[], 'rating':[], 'review':[]}\n",
    "for i in range(0,39):\n",
    "    url = 'https://www.metacritic.com/game/switch/animal-crossing-new-horizons/user-reviews?page=' + str(i)\n",
    "    user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers = user_agent)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for review in soup.find_all('div', class_='review_content'): \n",
    "        if review.find('div', class_='name') == None:\n",
    "            break \n",
    "        review_dict['name'].append(review.find('div', class_='name').find('a').text)\n",
    "        review_dict['date'].append(review.find('div', class_='date').text)\n",
    "        review_dict['rating'].append(review.find('div', class_='review_grade').find_all('div')[0].text)\n",
    "        if review.find('span', class_='blurb blurb_expanded'): \n",
    "            review_dict['review'].append(review.find('span', class_='blurb blurb_expanded').text)\n",
    "           # print(review.find('span', class_='blurb blurb_expanded').text)\n",
    "        elif review.find('div',class_='review_body').find('span') == None:\n",
    "            review_dict['review'].append('No review text.')\n",
    "           # print(\"No review\")\n",
    "        else:\n",
    "            review_dict['review'].append(review.find('div',class_='review_body').find('span').text)\n",
    "          #  print(review.find('div',class_='review_body').find('span').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_reviews = pd.DataFrame(review_dict)\n",
    "print(ac_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re_list = ['(https?://)?(www\\.)?(\\w+\\.)?(\\w+)(\\.\\w+)(/.+)?', '@[A-Za-z0-9_]+','#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Three: Use NLTK to tokenize the data, and chart a word cloud\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "token = WordPunctTokenizer()\n",
    "def cleaning_reviews(t):\n",
    "    del_amp = BeautifulSoup(t, 'lxml')\n",
    "    del_amp_text = del_amp.get_text()\n",
    "    del_link_mentions = re.sub(combined_re, '', del_amp_text)\n",
    "    del_emoticons = re.sub(regex_pattern, '', del_link_mentions)\n",
    "    lower_case = del_emoticons.lower()\n",
    "    words = token.tokenize(lower_case)\n",
    "    result_words = [x for x in words if len(x) > 2]\n",
    "    return (\" \".join(result_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = []\n",
    "for i in range(0,len(ac_reviews['review'])):\n",
    "    cleaned_reviews.append(cleaning_reviews((ac_reviews.review[i])))\n",
    "print(cleaned_reviews[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"animal\",\"crossing\",\"nintendo\",\"switch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = pd.Series(cleaned_reviews).str.cat(sep=' ')\n",
    "wordcloud = WordCloud(width=1600, stopwords=stopwords,height=800,max_font_size=200,max_words=50,collocations=False, background_color='white').generate(string)\n",
    "plt.figure(figsize=(40,30))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Four: Create a \"wordcloud of interest\" by playing with the visualization methods from the class demo, or others documented in the API\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "mask = np.array(Image.open('./nook.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=2000, mask = mask,stopwords=stopwords,height=1000,max_font_size=200,max_words=50,collocations=False,background_color='black').generate(string)\n",
    "f = plt.figure(figsize=(20,10))\n",
    "plt.imshow(mask, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "def green_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    return \"hsl(150, 50%%, %d%%)\" % random.randint(60, 100)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.imshow(wordcloud.recolor(color_func=green_color_func, random_state=3),\n",
    "           interpolation=\"bilinear\")\n",
    "plt.title('Animal Crossing', size='100')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Five: Import Bokeh and chart some aspect of the text: this could be the wordcount, topics, or sentiment analysis as demoed\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Next, we initialize VADER so we can use it within our Python script\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(text):\n",
    "    # Run VADER on the text\n",
    "    scores = sid.polarity_scores(text)\n",
    "    # Extract the compound score\n",
    "    compound_score = scores['compound']\n",
    "    # Return compound score\n",
    "    return compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_reviews['Sentiment Score'] = ac_reviews['review'].apply(calculate_sentiment)\n",
    "ac_reviews.sort_values(by='Sentiment Score', ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Viridis256\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models import ColorBar\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.models.tools import WheelZoomTool\n",
    "from bokeh.transform import jitter\n",
    "\n",
    "#file for output\n",
    "output_file(filename=\"ac.html\", title=\"AC Reviews Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_reviews['rating'] = ac_reviews['rating'].astype(int)\n",
    "source = ColumnDataSource(ac_reviews)\n",
    "mapper = linear_cmap(field_name='Sentiment Score', palette=Viridis256 ,low=-1 ,high=1)\n",
    "p = figure(plot_height=1000, plot_width=1000, toolbar_location=\"below\")\n",
    "p.circle(x=jitter('rating',width=1,range=p.x_range), y='Sentiment Score', source=source, size=5, line_color=mapper,color=mapper, fill_alpha=1)\n",
    "p.toolbar.active_scroll = WheelZoomTool()\n",
    "p.title.text = 'Animal Crossing Reviews'\n",
    "p.xaxis.axis_label = 'Review Score'\n",
    "p.yaxis.axis_label = 'Sentiment Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models.tools import PanTool, WheelZoomTool\n",
    "\n",
    "color_bar = ColorBar(color_mapper=mapper['transform'], width=8)\n",
    "p.background_fill_color = \"gray\"\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "hover = HoverTool()\n",
    "hover.tooltips= \"\"\"\n",
    "<div style=\"width:200px;\"><b>Review: </b>\n",
    "@review\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "p.add_tools(hover)\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598d64e08a06bfba065a99698ec5bbec753236817de80e4f3bcf221574aa140c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
