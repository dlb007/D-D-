{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise Eleven: PCA\n",
    "Drawing on our example from class and the discussion of PCA in Data-Sitters Club,\n",
    "\n",
    "Import at least ten documents from files, using the OS module and any others relevant to process the text\n",
    "Isolate a component (the example was nouns - try verbs or adjectives) using nltk and prepare appropriate sub-files for comparison on that axis\n",
    "Load the documents and titles and run the contents through vectorize, using the provided boilerplate\n",
    "Run a simple (2 word) vizualization comparing all texts\n",
    "Run a full (PCA) vizualization comparing all texts using the provided PCA boilerplate. Note any interesting characteristics or outliers in a brief analysis\n",
    "Bonus Challenge: This shows an example of collecting the texts from PDF files. Note it is also adjusted to handle shorter texts (rather than the novels from our previous example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE html><html lang=\"en\"><head><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" /><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" /><title>Film adaptations - Film Studies - Research Guides at Dartmouth College</title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"><meta name=\"robots\" content=\"noarchive\" /><!-- favicon.twig -->\\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/apple-touch-icon.png\">\\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/favicon-32x32.png\">\\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/favicon-16x16.png\">\\n<link rel=\"manifest\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/site.webmanifest\">\\n<link rel=\"mask-icon\" href=\"//libapps.s3.amazonaws.com/apps/common/favicon/safari-pinned-tab.svg\" color=\"#5bbad5\">\\n<link rel=\"shortcut icon\" href=\"//libapps.s3.amaz'\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import os\n",
    "\n",
    "textdir = 'C:\\\\DesignDevSyllabus\\\\exercises\\eleven\\\\pdf\\\\'\n",
    "os.chdir(textdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second (2) \n",
    "# save the website you are interested in as a file. \n",
    "# Name that file appropriately to the content - for instance, something like \"reviewarchive.html\" would make sense if you are pulling reviews of a movie or book. \n",
    "# After you run it, check that the file looks like it has the content you need. \n",
    "# If it doesn't, try to figure out what went wrong.\n",
    "\n",
    "url = 'https://researchguides.dartmouth.edu/filmstudies/adaptations'\n",
    "\n",
    "response = urllib.request.urlopen(url)\n",
    "webContent = response.read()\n",
    "\n",
    "f = open('screenadaptation.html', 'wb')\n",
    "f.write(webContent)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third (3) \n",
    "# append another page of connected content: you'll need to use a modified version of the previous code, changing the URL, and using \"append binary\" to add to the file.\n",
    "\n",
    "# Second, save the website you are interested in as a file. \n",
    "# Name that file appropriately to the content - for instance, something like \"reviewarchive.html\" would make sense if you are pulling reviews of a movie or book. \n",
    "# After you run it, check that the file looks like it has the content you need. \n",
    "# If it doesn't, try to figure out what went wrong.\n",
    "\n",
    "url = 'https://search.library.dartmouth.edu/discovery/fulldisplay?context=L&vid=01DCL_INST:01DCL&docid=alma991027986879705706'\n",
    "\n",
    "response = urllib.request.urlopen(url)\n",
    "webContent = response.read()\n",
    "\n",
    "f = open('texttoscreenscreentotext.html', 'ab')\n",
    "f.write(webContent)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen Adaptation\n"
     ]
    }
   ],
   "source": [
    "# (Bonus Challenge) \n",
    "# If you scraped something repetitive (for instance, I used two review pages from Rotten Tomatoes as I was testing my solution), \n",
    "# you'll notice you have a lot of redundancy in your file, and probably only a few things you really want. \n",
    "# Can you structure your data to only save the part of the webContent pull you are interested in? \n",
    "# (If you're new to programming or Python, or stressed for time this week, don't worry about the bonus rounds!)\n",
    "\n",
    "# Split can be used with any input you want\n",
    "# Array -ordered list of words instead of and ordered list of characters\n",
    "# box 1 split (again) from original string\n",
    "\n",
    "our_string = \"Screen Adaptation\"\n",
    "print(our_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 17\n"
     ]
    }
   ],
   "source": [
    "our_length = len(our_string)\n",
    "print(\"Length: \" + str(our_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of a: 9\n",
      "Occurences of l: 0\n",
      "Slice from index 3 to 8: een A\n"
     ]
    }
   ],
   "source": [
    "print(\"Index of a: \" + str(our_string.index(\"a\")))\n",
    "print(\"Occurences of l: \" + str(our_string.count(\"l\")))\n",
    "print(\"Slice from index 3 to 8: \" + our_string[3:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper case: SCREEN ADAPTATION\n",
      "Lower case: screen adaptation\n"
     ]
    }
   ],
   "source": [
    "print(\"Upper case: \" + our_string.upper())\n",
    "print(\"Lower case: \" + our_string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noitatpadA neercS\n"
     ]
    }
   ],
   "source": [
    "print(our_string[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptation\n"
     ]
    }
   ],
   "source": [
    "split_string = our_string.split(\" \")\n",
    "print(split_string[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(our_string.startswith(\"Screen\"))\n",
    "print(our_string.endswith(\"Adaptation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next (4)\n",
    "# Next, pull in the contents of the new file (with multiple pages of HTML) using our text file reading example from week one as a model. \n",
    "# Store those contents in a new variable, named appropriately to the contents. Print a subset of the output to confirm the import was successful.\n",
    "\n",
    "f = open('Screenadaptation.txt','w')\n",
    "f.write('Screen Adaptation')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen Adaptation\n"
     ]
    }
   ],
   "source": [
    "f = open('Screenadaptation.txt','r')\n",
    "message = f.read()\n",
    "print(message)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file-append.py\n",
    "f = open('Screenadaptation.txt','a')\n",
    "f.write('\\n' + 'Screen Adaptation')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of a: 9\n",
      "Occurences of l: 0\n",
      "Slice from index 2 to 10: reen Ada\n"
     ]
    }
   ],
   "source": [
    "# Finally (5)\n",
    "# Finally, use the examples in \"Conditionals.ipynb\" and \"PlayingWithStrings.ipynb\" to run at least five simple data analyses commands on your content \n",
    "# and print the results with an explanatory statement, as in the examples. Here's a few suggestions to try, but feel free to expand on them.\n",
    "\n",
    "# 1. Count and print the occurences of a key word\n",
    "\n",
    "# 2. Split your dataset into strings based on word spacing, and print some of the words to view the set\n",
    "\n",
    "# 3. Locate the index of a word of interest, then print the phrase surrounding it\n",
    "\n",
    "\n",
    "# Comparisons to help determine what we need to do with them (Conditional Statements)\n",
    "# make sur ecompare stings to strings and intergers to intergers, etc.\n",
    "# double =='s are comparisons\n",
    "\n",
    "print(\"Index of a: \" + str(our_string.index(\"a\")))\n",
    "print(\"Occurences of l: \" + str(our_string.count(\"l\")))\n",
    "print(\"Slice from index 2 to 10: \" + our_string[2:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper case: SCREEN ADAPTATION\n",
      "Lower case: screen adaptation\n"
     ]
    }
   ],
   "source": [
    "print(\"Upper case: \" + our_string.upper())\n",
    "print(\"Lower case: \" + our_string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "y = 2\n",
    "name = \"Dracula\"\n",
    "age = 1001\n",
    "print(x == y)\n",
    "print(x == 2)\n",
    "print(x < y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possibly Sherlock Homes.\n",
      "Found Hollywood.\n"
     ]
    }
   ],
   "source": [
    "# (5 Cont.)\n",
    "# 4. Compare the number of occurences of two significant words, such as character names, using a conditional statement. \n",
    "# The printed statement should be different for each outcome, and handle the case where the numbers are the same (try using if, elif, and else)\n",
    "\n",
    "# Comparison -Arrays (defining []) strings, etc.\n",
    "Hollywood = [\"Dracula\",\"Sherlock Homes\"]\n",
    "Bollywood = [\"Angoor\",\"The Lion King\"]\n",
    "# checks two conditions (name and age)\n",
    "# == asking\n",
    "if name == \"Sherlock Homes\" and age == 1001:\n",
    "    print(\"Dracula verified.\")\n",
    "\n",
    "# checks two conditions and is true if at least one is true\n",
    "if name == \"Sherlock Homes\" or age == 1001:\n",
    "    print(\"Possibly Sherlock Homes.\")\n",
    "\n",
    "# 5. Search for a word and use \"in\" to print true if the word is found\n",
    "\n",
    "# check if name exists in array, true if it does \"in\" keyword\n",
    "# if name isn't in that thing, check if instead it's in rubbles\n",
    "# if it isn't in either thing, print that it isn't a character\n",
    "if name in Hollywood:\n",
    "    print(\"Found Hollywood.\")\n",
    "elif name in Bollywood:\n",
    "    print(\"Found Bollywood.\")\n",
    "else:\n",
    "    print(\"Not a character.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Angoor', 'The Lion King']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "name = \"Angoor\"\n",
    "age = 23\n",
    "\n",
    "rubble = name in Bollywood\n",
    "print(Bollywood)\n",
    "print(not Bollywood)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598d64e08a06bfba065a99698ec5bbec753236817de80e4f3bcf221574aa140c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
