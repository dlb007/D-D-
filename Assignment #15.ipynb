{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Fourteen: Project Design Starter\n",
    "In this exercise, you'll be planning out a complex project. You'll draw in some code, but focus on commenting to describe your project structure. The sample document below will guide you through organizing and annotating your project design. The primary components you'll include are:\n",
    "\n",
    "- Dependencies: What modules will your project need?\n",
    "- Collection: Where is your data coming from?\n",
    "- Processing: How will you format and process your data?\n",
    "- Analysis: What techniques will you use to understand your data?\n",
    "- Visualization: How will you visualize and explore your data?\n",
    "\n",
    "Don't worry if you aren't exactly certain how you would implement everything - this should be a starting point for a larger research study, but it doesn't need to be a complete, functional workflow. Aim for a \"good enough\" starting point that you can reference and extend for future work.\n",
    "\n",
    "Note where you have something working, and where it's broken or in progress.\n",
    "\n",
    "Race After Technology: Chapter 5\n",
    "Digital Humanities Coursebook: Coda\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"When people change how they speak or act in order to conform to dominant norms, we call it “code-switching”\" (Benjamin 180). \n",
    "\n",
    "\"Data, in short, do not speak for themselves and don’t always change hearts and minds or policy\" (Benjamin 192). \n",
    "\n",
    "And to help push the technical philosophy further and keep the process moving was knowing that \"An interface is a set of cognitive cues. It may look like a screen full of pictures of things inside the computer, but in fact, the interface mediates between an individual the computational activity\" (Drucker 176)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview: NaNoGenMo\n",
    "This sample project builds on our previous exercises inspired by National Novel Generation Month. It offers a framework for exporing text generation based upon children's literature, inspired by NaNoGenMo's call to think about different forms of procedural making. As such, it is guided by that project's rule: \"Spend the month of November writing code that generates a novel of 50k+ words.\"\n",
    "\n",
    "(Replace this text with a short description of what your envisioned project design will accomplish. Include your research question and goals for this analysis.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage One: Dependencies\n",
    "\n",
    "Add the import code for every dependency of your project: for instance, if you are collecting data, you might import Tweepy or BeautifulSoup. If you're working with a file of folders, import os. Most projects will require Pandas, along with appropriate processing and visualization libraries. In the comments, explain briefly why you are including each library (as shown in the example below.)\n",
    "\n",
    "\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas to handle collected Twitter data (example comment)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, comfort has been established as BeautifulSoup enables movement to work without an API. Enforcing beginning with \"a problem or a question. If your problem or question is not well defined, develop or find one which is\" (Karsdorp, Kestemont, Riddell 323) comes alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Two: Collection\n",
    "Describe your data collection scope and process briefly, and include an example of how you might collect your data drawing on our other projects. For example, if this workflow will collect Twitter data from a stream, you might revisit that demo, copy the stream, and adjust the hashtag.\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data using a Tweepy stream (example annotation)\n",
    "# (Copy and modify code from other exercises to prototype this goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Package imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "import concurrent.futures\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the use of exploring the URL of interest, https://www.metacritic.com/game/playstation-3/the-walking-dead-a-telltale-games-series/user-reviews?page=, it allowed for the process to “Consider many models. Different narratives are often compatible with the same set of observations” (Karsdorp, Kestemont, Riddell 324)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict = {'name':[], 'date':[], 'rating':[], 'review':[]}\n",
    "for i in range(0, 50):\n",
    "    url = 'https://www.metacritic.com/game/playstation-3/the-walking-dead-a-telltale-games-series/user-reviews?page=' + str(i)\n",
    "    user_agent = {'User-agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers = user_agent)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for review in soup.find_all('div', class_='review_content'): \n",
    "        if review.find('div', class_='name') == None:\n",
    "            break \n",
    "        review_dict['name'].append(review.find('div', class_='name').find('a').text)\n",
    "        review_dict['date'].append(review.find('div', class_='date').text)\n",
    "        review_dict['rating'].append(review.find('div', class_='review_grade').find_all('div')[0].text)\n",
    "        if review.find('span', class_='blurb blurb_expanded'): \n",
    "            review_dict['review'].append(review.find('span', class_='blurb blurb_expanded').text)\n",
    "           # print(review.find('span', class_='blurb blurb_expanded').text)\n",
    "        elif review.find('div',class_='review_body').find('span') == None:\n",
    "            review_dict['review'].append('No review text.')\n",
    "           # print(\"No review\")\n",
    "        else:\n",
    "            review_dict['review'].append(review.find('div',class_='review_body').find('span').text)\n",
    "          #  print(review.find('div',class_='review_body').find('span').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Three: Processing\n",
    "After your data has been collected or imported, store it in a format that works for your purposes. This can vary: for Twitter analysis, it might be a Pandas dataframe, while for text, you might build a document term matrix.\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Twitter data using Pandas with appropriate column names (example comment)\n",
    "# (Copy and modify code from other exercises to prototype this goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Pandas' data frame was a smooth process, which contributed to the fun lines allowing for an \"Account for variability in human judgments\" (Karsdorp, Kestemont, Riddell 324), enabling organizational aspects toward the coding journey to become more formulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_reviews = pd.DataFrame(review_dict)\n",
    "print(ac_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Four: Analysis\n",
    "Think across all of the methods we've tried this semester - what combination would be most helpful for your goals? Include code sections for each method you think is important. In most cases, a combination will be most revealing: for instance, you might employ several different textual analysis frameworks on a set of documents. Use at least two distinctly different methods of analysis.\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare several account outputs using PCA (example comment)\n",
    "# (Copy and modify code from other exercises to prototype this goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to clean up and help remove characters etc., as BeautifulSoup enabled significant aspects of cleaning setup, exploring \"ideas from math and (Bayesian) statistics. Good ideas are found everywhere\" (Karsdorp, Kestemont, Riddell 324)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re_list = ['(https?://)?(www\\.)?(\\w+\\.)?(\\w+)(\\.\\w+)(/.+)?', '@[A-Za-z0-9_]+','#']\n",
    "combined_re = re.compile( '|'.join( re_list) )\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "token = WordPunctTokenizer()\n",
    "def cleaning_reviews(t):\n",
    "    del_amp = BeautifulSoup(t, 'lxml')\n",
    "    del_amp_text = del_amp.get_text()\n",
    "    del_link_mentions = re.sub(combined_re, '', del_amp_text)\n",
    "    del_emoticons = re.sub(regex_pattern, '', del_link_mentions)\n",
    "    lower_case = del_emoticons.lower()\n",
    "    words = token.tokenize(lower_case)\n",
    "    result_words = [x for x in words if len(x) > 2]\n",
    "    return (\" \".join(result_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = []\n",
    "for i in range(0,len(ac_reviews['review'])):\n",
    "    cleaned_reviews.append(cleaning_reviews((ac_reviews.review[i])))\n",
    "print(cleaned_reviews[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"walking\",\"dead\",\"telltale\",\"kill\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used variance in code and color, and size enabled for visualized experimentation and expression, as \"The creation of digital assets will then serve the project's overall design\" (Drucker 193)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = pd.Series(cleaned_reviews).str.cat(sep=' ')\n",
    "wordcloud = WordCloud(width=1600, stopwords=stopwords,height=1000,max_font_size=250,max_words=100,collocations=False, background_color='blue').generate(string)\n",
    "plt.figure(figsize=(40,30))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Five: Visualization\n",
    "Finally, think about the visualizations that would be most useful to sharing and exploring your data. Consider both static and dynamic approaches from the different libraries we've worked with this semester. Include at least two preliminary visualizations.\n",
    "\n",
    "(Karsdorp, Kestemont, and Riddell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a wordcloud of term distributions in each document (example comment)\n",
    "# (Copy and modify code from other exercises to prototype this goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "mask = np.array(Image.open('Walk.PNG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took out subplots and changed toward variance of color. A higher-resolution image can be achieved by funding fixed color numbers and adjusting the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=2000, mask = mask,stopwords=stopwords,height=1000,max_font_size=250,max_words=100,collocations=False,background_color='violet').generate(string)\n",
    "f = plt.figure(figsize=(40,30))\n",
    "plt.imshow(mask, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "def green_color_func(word, font_size, position, orientation, random_state=None,\n",
    "                    **kwargs):\n",
    "    return \"hsl(150, 50%%, %d%%)\" % random.randint(60, 100)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.imshow(wordcloud.recolor(color_func=green_color_func, random_state=3),\n",
    "           interpolation=\"bilinear\")\n",
    "plt.title('The Walking Dead', size='100')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage Five: Import Bokeh and chart some aspect of the text: this could be the wordcount, topics, or sentiment analysis as demoed\n",
    "A sentiment drew interest in charting differences in a sentiment score, which became the range of judgments, signifying that “Knowledge of the existing tools and platforms for this aspect of research is important” (Drucker 199)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Next, we initialize VADER so we can use it within our Python script\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(text):\n",
    "    # Run VADER on the text\n",
    "    scores = sid.polarity_scores(text)\n",
    "    # Extract the compound score\n",
    "    compound_score = scores['compound']\n",
    "    # Return compound score\n",
    "    return compound_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_reviews['Sentiment Score'] = ac_reviews['review'].apply(calculate_sentiment)\n",
    "ac_reviews.sort_values(by='Sentiment Score', ascending=False)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES: New with color pallets etc., tried \"jitter\" and palettes import. Review scores are numerical were as the \"jitter\" brings in due to being applied to the bar space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.palettes import Viridis256\n",
    "from bokeh.models.tools import HoverTool\n",
    "from bokeh.models.formatters import DatetimeTickFormatter\n",
    "from bokeh.models import ColorBar\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.models.tools import WheelZoomTool\n",
    "from bokeh.transform import jitter\n",
    "\n",
    "#file for output\n",
    "output_file(filename=\"ac.html\", title=\"AC Reviews Visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I experimented with the range and size of indicators, etc., as “A platform with a broad user community is more likely to last—and to provide help support in the form of list-servs and other venues” (Drucker 199)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_reviews['rating'] = ac_reviews['rating'].astype(int)\n",
    "source = ColumnDataSource(ac_reviews)\n",
    "mapper = linear_cmap(field_name='Sentiment Score', palette=Viridis256 ,low=-3 ,high=2)\n",
    "p = figure(plot_height=1000, plot_width=1000, toolbar_location=\"below\")\n",
    "p.circle(x=jitter('rating',width=2,range=p.x_range), y='Sentiment Score', source=source, size=10, line_color=mapper,color=mapper, fill_alpha=1)\n",
    "p.toolbar.active_scroll = WheelZoomTool()\n",
    "p.title.text = 'The Walking Dead Reviews'\n",
    "p.xaxis.axis_label = 'Review Score'\n",
    "p.yaxis.axis_label = 'Sentiment Score'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it is light in modes, HTML visual presentation, does show the separation of scores of sentiment, etc., separated by light and dark components, as \"a repository like GitHub ...is an invaluable resource for anyone working on digital project development” (Drucker 208)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models.tools import PanTool, WheelZoomTool\n",
    "\n",
    "color_bar = ColorBar(color_mapper=mapper['transform'], width=8)\n",
    "p.background_fill_color = \"gray\"\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "hover = HoverTool()\n",
    "hover.tooltips= \"\"\"\n",
    "<div style=\"width:200px;\"><b>Review: </b>\n",
    "@review\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "p.add_tools(hover)\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "598d64e08a06bfba065a99698ec5bbec753236817de80e4f3bcf221574aa140c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
